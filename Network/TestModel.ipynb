{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2 as transformsV2\n",
    "from torch.utils.data import DataLoader\n",
    "from Dataset import MyDataset\n",
    "from tqdm import tqdm\n",
    "from Network import MyNetwork\n",
    "import os\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda:0\n"
     ]
    }
   ],
   "source": [
    "MEAN = np.array([0.5750, 0.6065, 0.6459])\n",
    "STD = np.array([0.1854, 0.1748, 0.1794])\n",
    "ROOT_DIRECTORY = \"c:\\\\Users\\\\jacop\\\\Desktop\\\\BSc\\\\Code\\\\WindTurbineImagesCategorization\\\\Data\\\\Dataset\"\n",
    "# ROOT_DIRECTORY = \"/zhome/f9/0/168881/Desktop/WindTurbineImagesCategorization/Data/Dataset\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device in use: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable), total=len(iterable), ncols=150, desc=desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transformsV2.Compose([\n",
    "    transformsV2.Resize((224, 224)),\n",
    "    transformsV2.RandomHorizontalFlip(p=0.5),\n",
    "    transformsV2.RandomVerticalFlip(p=0.5),\n",
    "    transformsV2.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "    transformsV2.RandomAutocontrast(p=0.5),\n",
    "    transformsV2.RandomRotation(degrees=[0, 90]),\n",
    "    transformsV2.ColorJitter(brightness=0.25, saturation=0.20),\n",
    "    # Replace deprecated ToTensor()\n",
    "    transformsV2.ToImage(),\n",
    "    transformsV2.ToDtype(torch.float32, scale=True),\n",
    "    transformsV2.Normalize(mean=MEAN.tolist(), std=STD.tolist()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"input channels\": 3,\n",
    "    \"number of classes\": 5,\n",
    "    \"split\": {\"train\": 0.6, \"val\": 0.2, \"test\": 0.2},\n",
    "    \"batch size\": 32,\n",
    "    \"number of workers\": 0,\n",
    "    \"learning rate\": 0.0002,\n",
    "    \"epochs\": 100,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"epsilon\": 1e-08,\n",
    "    \"weight decay\": 1e-08,\n",
    "    \"step size\": 33,\n",
    "    \"gamma\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS AND DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new Dataset for training of length: 1320\n",
      "Created a new Dataset for validation of length: 440\n",
      "Created a new Dataloader for training with batch size: 32\n",
      "Created a new Dataloader for validation with batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Create Datasets and Dataloaders\n",
    "dataset_train = MyDataset(root_directory=ROOT_DIRECTORY, mode=\"train\",\n",
    "                          transform=transform, split=hyper_parameters[\"split\"], pca=False)\n",
    "print(f\"Created a new Dataset for training of length: {len(dataset_train)}\")\n",
    "dataset_validation = MyDataset(root_directory=ROOT_DIRECTORY,\n",
    "                               mode=\"val\", transform=None, split=hyper_parameters[\"split\"], pca=False)\n",
    "print(f\"Created a new Dataset for validation of length: {\n",
    "      len(dataset_validation)}\")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=hyper_parameters[\"batch size\"], shuffle=True, num_workers=hyper_parameters[\"number of workers\"], drop_last=False)\n",
    "print(f\"Created a new Dataloader for training with batch size: {\n",
    "      hyper_parameters[\"batch size\"]}\")\n",
    "dataloader_validation = DataLoader(dataset_validation, batch_size=hyper_parameters[\"batch size\"], shuffle=True,\n",
    "                                   num_workers=hyper_parameters[\"number of workers\"], drop_last=False)\n",
    "print(f\"Created a new Dataloader for validation with batch size: {\n",
    "      hyper_parameters[\"batch size\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, move to cuda:0 and weights initialized\n"
     ]
    }
   ],
   "source": [
    "# Create Model, initialize its weights, create optimizer and loss function\n",
    "model = MyNetwork(hyper_parameters)\n",
    "model.weight_initialization()\n",
    "model.to(DEVICE)\n",
    "print(f\"Model created, move to {DEVICE} and weights initialized\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=hyper_parameters[\"learning rate\"],\n",
    "                       betas=(hyper_parameters[\"beta1\"],\n",
    "                              hyper_parameters[\"beta2\"]),\n",
    "                       weight_decay=hyper_parameters[\"weight decay\"],\n",
    "                       eps=hyper_parameters[\"epsilon\"])\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=hyper_parameters[\"step size\"], gamma=hyper_parameters[\"gamma\"])\n",
    "# Empty memory before start\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSOR BOARD LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the path for saving logs\n",
    "logs_dir = 'WindTurbineImagesCategorization\\\\Network\\\\runs'\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "num_of_runs = len(os.listdir(logs_dir))\n",
    "run_dir = os.path.join(logs_dir, f'run_{num_of_runs + 1}')\n",
    "logger = SummaryWriter(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_classifier(classifier, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\"):\n",
    "def train_net(model, loss_function, device, dataloader_train, dataloader_validation, optimizer, hyper_parameters, logger, scheduler, name=\"default\"):\n",
    "    epochs = hyper_parameters[\"epochs\"]\n",
    "\n",
    "    validation_loss = 0\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        \"\"\"    Train step for one batch of data    \"\"\"\n",
    "        training_loop = create_tqdm_bar(\n",
    "            dataloader_train, desc=f'Training Epoch [{epoch+1}/{epochs}]')\n",
    "\n",
    "        training_loss = 0\n",
    "        model.train()  # Set the model to training mode\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad()  # Reset the parameter gradients for the current minibatch iteration\n",
    "\n",
    "            images, labels = batch\n",
    "            labels -= 1  # Change the labels to start from 0\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass, backward pass and optimizer step\n",
    "            predicted_labels = model(images)\n",
    "            loss_train = loss_function(predicted_labels, labels)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss and calculate the accuracy of predictions\n",
    "            training_loss += loss_train.item()\n",
    "\n",
    "            # Running train accuracy\n",
    "            _, predicted = predicted_labels.max(1)\n",
    "            num_correct = (predicted == labels).sum()\n",
    "            train_accuracy = float(num_correct)/float(images.shape[0])\n",
    "\n",
    "            training_loop.set_postfix(train_loss=\"{:.8f}\".format(\n",
    "                training_loss / (train_iteration + 1)), val_loss=\"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            logger.add_scalar(f'{name}/train_loss', loss_train.item(),\n",
    "                              epoch*len(dataloader_train)+train_iteration)\n",
    "            logger.add_scalar(f'{name}/train_accuracy', train_accuracy,\n",
    "                              epoch*len(dataloader_train)+train_iteration)\n",
    "\n",
    "        \"\"\"    Validation step for one batch of data    \"\"\"\n",
    "        val_loop = create_tqdm_bar(\n",
    "            dataloader_validation, desc=f'Validation Epoch [{epoch+1}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                labels -= 1  # Change the labels to start from 0\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(images)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss_val = loss_function(output, labels)\n",
    "\n",
    "                validation_loss += loss_val.item()\n",
    "\n",
    "                val_loop.set_postfix(val_loss=\"{:.8f}\".format(\n",
    "                    validation_loss/(val_iteration+1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                logger.add_scalar(f'{name}/val_loss', validation_loss/(\n",
    "                    val_iteration+1), epoch*len(dataloader_validation)+val_iteration)\n",
    "\n",
    "        # This value is for the progress bar of the training loop.\n",
    "        validation_loss /= len(dataloader_validation)\n",
    "\n",
    "        logger.add_scalars(f'{name}/Combined', {'val_loss': validation_loss,\n",
    "                                                'train_loss': training_loss/len(dataloader_train)}, epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "        print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/100]:  24%|█████████▎                             | 10/42 [00:06<00:19,  1.66it/s, train_loss=3620655.99890685, val_loss=0.00000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_net(model, loss_function, DEVICE, dataloader_train,\n\u001b[0;32m      2\u001b[0m           dataloader_validation, optimizer, hyper_parameters, logger, scheduler, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mtrain_net\u001b[1;34m(model, loss_function, device, dataloader_train, dataloader_validation, optimizer, hyper_parameters, logger, scheduler, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m training_loop \u001b[38;5;241m=\u001b[39m create_tqdm_bar(\n\u001b[0;32m     10\u001b[0m     dataloader_train, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_iteration, batch \u001b[38;5;129;01min\u001b[39;00m training_loop:\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset the parameter gradients for the current minibatch iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jacop\\Desktop\\BSc\\Code\\WindTurbineImagesCategorization\\Network\\Dataset.py:133\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_image_as_numpy(path)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    135\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_and_test_transform(image)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m transform(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\_transform.py:51\u001b[0m, in \u001b[0;36mTransform.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[0;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[0;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[0;32m     53\u001b[0m ]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\_geometry.py:145\u001b[0m, in \u001b[0;36mResize._transform\u001b[1;34m(self, inpt, params)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, inpt: Any, params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_kernel(\n\u001b[0;32m    146\u001b[0m         F\u001b[38;5;241m.\u001b[39mresize,\n\u001b[0;32m    147\u001b[0m         inpt,\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize,\n\u001b[0;32m    149\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation,\n\u001b[0;32m    150\u001b[0m         max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size,\n\u001b[0;32m    151\u001b[0m         antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias,\n\u001b[0;32m    152\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[1;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     34\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel(inpt, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\functional\\_geometry.py:310\u001b[0m, in \u001b[0;36m__resize_image_pil_dispatch\u001b[1;34m(image, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m antialias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _resize_image_pil(image, size\u001b[38;5;241m=\u001b[39msize, interpolation\u001b[38;5;241m=\u001b[39minterpolation, max_size\u001b[38;5;241m=\u001b[39mmax_size)\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\torchvision\\transforms\\v2\\functional\\_geometry.py:297\u001b[0m, in \u001b[0;36m_resize_image_pil\u001b[1;34m(image, size, interpolation, max_size)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (new_height, new_width) \u001b[38;5;241m==\u001b[39m (old_height, old_width):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\u001b[38;5;241m.\u001b[39mresize((new_width, new_height), resample\u001b[38;5;241m=\u001b[39mpil_modes_mapping[interpolation])\n",
      "File \u001b[1;32mc:\\Users\\jacop\\anaconda3\\envs\\TurbineModel\\Lib\\site-packages\\PIL\\Image.py:2200\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2192\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2193\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2194\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2195\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2196\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2197\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2198\u001b[0m         )\n\u001b[1;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mresize(size, resample, box))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_net(model, loss_function, DEVICE, dataloader_train,\n",
    "          dataloader_validation, optimizer, hyper_parameters, logger, scheduler, name=\"Def\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"WindTurbineImagesCategorization\\\\Network\\\\Results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
